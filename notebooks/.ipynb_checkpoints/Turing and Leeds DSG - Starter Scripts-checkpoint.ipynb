{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turing and Leeds Data Study Group\n",
    "========================\n",
    "\n",
    "OSNI | Starter scripts \n",
    "-------------------------------\n",
    "\n",
    "Griff Rees, Stephen Law, Andrew Elliott.\n",
    "\n",
    "Welcome to the OSNI DSG. This is a short notebook to help you get started on the DSG challenge for those that aren't familiar with image processing techniques and the handling of lidar data. The short notebook consists of three parts. \n",
    "\n",
    "1. hands-on CNN with tensorflow.keras\n",
    "\n",
    "2. hands-on CNN with Pytorch\n",
    "\n",
    "3. hands-on LIDAR data in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Hands-on CNN with tensorflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVuFU7yzfLvU"
   },
   "source": [
    "First, we will go over some basics in training a convolutional neural network on image data with the tensorflow.keras package. CNN is a popular and useful technique in deep learning which  achieves human-level accuracy for a series of tasks including scene recognition and object detection. \n",
    "\n",
    "```!pip install tensorflow```\n",
    "\n",
    "**Reference** <br/>\n",
    "Materials in this lab had been adapted from; \n",
    "* Turing intro to cnn workshop conducted by Stephen Law and Chanuki Serensinhe.\n",
    "* UCL Geography intro to CNN workshop with cifar images conducted by Stephen Law and Alfie Long.\n",
    "* Machine Learning Mastery, 2019. Your First Deep Learning Project in Python with Keras Step-By-Step tutorial. Accessed from:\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "* Keras official api. Accessed from: https://keras.io/getting_started/intro_to_keras_for_researchers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line just ignores the warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "P1LH0dRIWJm1",
    "outputId": "3c41aeaa-0214-40dc-c3cf-a41a5a21e51a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Running CNN on CIFAR-10 dataset\n",
    "\n",
    "In this tutorial we will walk you through building your first convolutional neural network and training it using the CIFAR-10 dataset. The CIFAR-10 dataset (Canadian Institute For Advanced Research)  is a collection of images that are commonly used to train machine learning and computer vision algorithms. It contains 60,000 images with 10 classes. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them. The dataset has the following classes. \n",
    "\n",
    "0: airplane <br/>\n",
    "1: automobile <br/>\n",
    "2: bird <br/>\n",
    "3: cat <br/>\n",
    "4: deer <br/>\n",
    "5: dog <br/>\n",
    "6: frog <br/>\n",
    "7: horse <br/>\n",
    "8: ship <br/>\n",
    "9: truck <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "oYzn4N49KXaN",
    "outputId": "5a48be8c-7f36-4b72-dabc-a461057c09cc"
   },
   "outputs": [],
   "source": [
    "# let's load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# summarize loaded dataset\n",
    "print(f'X_train shape : {X_train.shape}')\n",
    "print(f'y_train shape : {y_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}')\n",
    "print(f'y_test shape : {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's plot the first couple of images to see what the data looks like. As you can see these are low resolution color images for the ten cifar classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first few images\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1UEfFLSZKg-"
   },
   "source": [
    "### Let's build a simple sequential CNN model for scene recognition\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png\"> \n",
    "\n",
    "*image source: https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png*\n",
    "\n",
    "The heart of CNN model are these stacks of Convolutional blocks which are made up of a series of *keras.layers.Conv2D* and *keras.layers.maxpooling2D* layers. The Conv2D layer is similar to the dense layer with the addition of the convolutional filters. The MaxPool layer on the other hand is a subsampling layer. \n",
    "A convolutional blocks are essentially stacks of these two layers. You can also include Dropout layers like in the last lecture. Here we will use the Sequential layers similar to a normal MLP. There are different ways to construct a CNN but the sequential class is the easiest way to begin. Here is how a typical conv block would look like. A VGG16 which we will use a little later is effectively a series of these Conv blocks stack on top of each other.\n",
    "\n",
    "```python\n",
    "# typical Conv Block\n",
    "keras.layers.Conv2D(output_dim, (filter size), activation, input_dim)\n",
    "keras.layers.MaxPooling2D((filter size))\n",
    "Dropout(0.25)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "hBDJolo2ZgNS",
    "outputId": "8b3ed522-199c-4e91-93f8-532518fbcd61"
   },
   "outputs": [],
   "source": [
    "def sequential_model(width, height, depth, classes):\n",
    "    # initialize the model along with the input shape\n",
    "    model = models.Sequential()\n",
    "    input_shape = (height, width, depth)\n",
    "    \n",
    "    #Conv Block 1\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    \n",
    "    #Conv Block 2 \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    \n",
    "    #Conv Block 3\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "    \n",
    "    # Flatten the 3D tensor into a 1D vector\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(classes))\n",
    "    model.add(layers.Activation(\"softmax\"))\n",
    "    \n",
    "    # Display the architecture of our model\n",
    "    model.summary()\n",
    "    \n",
    "    # Return the constructed network architecture\n",
    "    return model\n",
    "\n",
    "model = sequential_model(32, 32, 3, len(class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUxZuK7kxsep"
   },
   "source": [
    "### Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKRjue-eaR-T"
   },
   "outputs": [],
   "source": [
    "# scale the data to the range [0, 1]\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "y_train_cat =tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tlL1JyxxzX-"
   },
   "source": [
    "### Training a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train a ConvNet using the fit function. \n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size, epochs)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the initial learning rate, batch size, and number of epochs to train for\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Initialize the optimizer and compile the model. \n",
    "optimiser_function = SGD(lr=learning_rate, momentum=0.9)\n",
    "model.compile(optimizer=optimiser_function, loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network \n",
    "history = model.fit(X_train, y_train_cat, batch_size=batch_size,validation_data=(X_test, y_test_cat),epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSNIa_LpFUaO"
   },
   "source": [
    "### Plot the training loss and accuracy\n",
    "you can then plot the training loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "9xBLEFVQamlW",
    "outputId": "cae6b60c-5637-4632-8cd7-b02547cee6aa"
   },
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,2,figsize=(12,6))\n",
    "ax[0].set_title(\"Train and Val Loss on CIFAR-10\")\n",
    "ax[0].plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "ax[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "ax[0].set_xlabel(\"Epoch #\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_title(\"Training and Val Acc on CIFAR-10\")\n",
    "ax[1].plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "ax[1].plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "ax[1].set_xlabel(\"Epoch #\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOK-AznnFZCU"
   },
   "source": [
    "### Evaluate the predictions\n",
    "\n",
    "let's evaluate the prediction. this can simply be done by using the evaluate method in model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,acc=model.evaluate(X_test,y_test_cat)\n",
    "print (f'loss: {loss}')\n",
    "print (f'accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also produce a confusion matrix between all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "fig,ax=plt.subplots(figsize=(12,10))\n",
    "y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "df=pd.DataFrame(confusion_matrix(y_test_cat.argmax(axis=1), y_pred.argmax(axis=1)),index=class_names,columns=class_names)\n",
    "sns.heatmap(df, annot=True,linewidths=.5, cmap=\"Blues\", fmt=\".1f\", ax=ax )\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HSM0g8DFm9i"
   },
   "source": [
    "### Plot the predictions\n",
    "finally let's plot the image, its observed label and its corresponding predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image):\n",
    "    img = image.astype('float32')\n",
    "    img_tensor = np.expand_dims(img, axis=0)                       \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_labels = np.array(class_names)\n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize=(10,10))\n",
    "for i in range(5):\n",
    "    index = random.randint(0, X_test.shape[0])\n",
    "    img = X_test[index]\n",
    "    img_tensor= load_image(img)\n",
    "    label = (np.where(y_test_cat[index] == 1)[0][0])\n",
    "    y_pred=model.predict(img_tensor)\n",
    "    best_class = np.argmax(y_pred)\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(cifar10_labels[label]+'_'+cifar10_labels[best_class])\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get a pretrained-model from Keras (VGG16)\n",
    "We typically recommend getting a pretrained VGG16 CNN model when training a classifier. \n",
    "\n",
    "```python\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False\n",
    "```\n",
    "\n",
    "\n",
    "*Reference* <br/>\n",
    "Simonyan and Zisserman (2015)Very Deep Convolutional Networks for Large-Scale Image Recognition. ICLR2015.\n",
    "\n",
    "https://keras.io/api/applications/vgg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = np.expand_dims(cv2.resize(img_tensor.squeeze(), (224, 224), interpolation=cv2.INTER_CUBIC),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'predicted probabilities: {base_model.predict(img_tensor).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Hands-on CNN with Pytorch\n",
    "\n",
    "We will go over similar steps in training a convolutional neural network on image data with the Pytorch package. The tutorial is adapted from the two tutorials listed below. \n",
    "\n",
    "```!pip install pytorch``` \n",
    "\n",
    "```!pip install torchvision```\n",
    "\n",
    "\n",
    "**Reference** <br/>\n",
    "Materials in this section had been adapted from; \n",
    "\n",
    "Rensu Theart Tutorial\n",
    "https://github.com/rensutheart/PyTorch-Deep-Learning-Tutorials/blob/master/part3_5_MNIST_Sequential.py\n",
    "\n",
    "Pytorch Official Tutorial\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Running CNN on CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# for Datasets\n",
    "import torchvision\n",
    "from torchvision import datasets,models, transforms, utils\n",
    "\n",
    "# to plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for timing\n",
    "import timeit\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialise parameters for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images in a batch\n",
    "batch_size = 4\n",
    "\n",
    "# window size of a filter\n",
    "kernel_size = 5\n",
    "\n",
    "# number of epochs to run\n",
    "epochs = 3\n",
    "\n",
    "# learning rate for SGD\n",
    "learning_rate = 0.001\n",
    "\n",
    "# storing the losses\n",
    "loss_array = []\n",
    "epoch_loss_array = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image dataset - CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise function for CiFAR10 dataset \n",
    "# Pytorch tutorials normalise by mean: (0.5,0.5,0.5) and std: (0.5,0.5,0.5) \n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this downloads the train and test dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "\n",
    "# this loads the train and test dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "# these are the classes for Cifar\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining up the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # 400 flat features\n",
    "        flat = num_flat_features(x)\n",
    "        x = x.view(-1, flat)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Finding out dimension of flattened layer\n",
    "def num_flat_features(x):\n",
    "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimiser :  gradient decent (define the learning rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clear tensorflow GPU memory to make enough space for \n",
    "# pytorch to run\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array=[]\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print((epoch + 1, i + 1, running_loss / 1000))\n",
    "            loss_array.append(running_loss/1000)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss\n",
    "plt.plot(loss_array)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Getting a pretrained-model from PyTorch (VGG16)\n",
    "\n",
    "You can similarly get a pretrained-model from Pytorch.\n",
    "\n",
    "**Reference** <br/>\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.vgg16(pretrained=True)\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Hands-on Lidar Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 LasPy\n",
    "\n",
    "LAS (and it’s compressed counterpart LAZ), is a popular format for lidar pointcloud. The laspy library reads and writes these formats and provides a Python API via Numpy Arrays.\n",
    "\n",
    "```!pip install laspy```\n",
    "\n",
    "\n",
    "https://laspy.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install laspy[lazrs,laszip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "from laspy.file import File\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O autzen.laz https://github.com/PDAL/data/blob/master/workshop/autzen.laz?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laspy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'autzen.laz'\n",
    "# this line works with the new laspy (2.0)\n",
    "las = laspy.read(path)\n",
    "# this line works with the old laspy (1.2)\n",
    "#las = File(path, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = np.vstack([las.X, las.Y, las.Z]).transpose()\n",
    "dataset1.shape\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(las.X[:],las.Y[:],s=0.0001,color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = np.vstack([las.X, las.Y, las.Z]).transpose()\n",
    "dataset1.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tensorflow_CNN_Intro_Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
